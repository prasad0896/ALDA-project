{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import TimeSeriesSplit as tscv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as efs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_to_numeric(x):\n",
    "    if x=='W' or x=='w' or x==0.633047:\n",
    "        return 1\n",
    "    elif x=='L' or x=='l':\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "df = pd.read_csv('finalDataset.csv', sep=',')\n",
    "df = df.drop(['PtDiff'],axis=1)\n",
    "df['WL'] = df['WL'].apply(result_to_numeric)\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.values[:,3:12],\n",
    "    df.values[:,-1],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    shuffle=False)\n",
    "\n",
    "y_train = y_train.astype('int')\n",
    "y_test = y_test.astype('int')\n",
    "\n",
    "print('Training dataset shape:', X_train.shape, y_train.shape)\n",
    "print('Testing dataset shape:', X_test.shape, y_test.shape)\n",
    "print(df['WL'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegressionCV(cv= tscv(n_splits = 5), random_state=42,solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build step forward feature selection\n",
    "efs1 = efs(clf,\n",
    "           min_features=1,\n",
    "           max_features=9,\n",
    "           scoring='accuracy',\n",
    "           print_progress=True,\n",
    "           cv = tscv(n_splits = 5))\n",
    "\n",
    "sfs1 = sfs(clf,\n",
    "           k_features='best',\n",
    "           scoring='accuracy',\n",
    "           verbose=2,\n",
    "           cv=tscv(n_splits = 5))\n",
    "\n",
    "# Perform SFFS\n",
    "efs1 = efs1.fit(X_train, y_train)\n",
    "\n",
    "#Perform SFFS\n",
    "sfs1 = sfs1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efs1.best_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efs1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs1.k_feature_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs1.k_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sfs lr acc\n",
    "clf.fit(X_train[:,list(sfs1.k_feature_idx_)],y_train)\n",
    "y_sfs_pred = clf.predict(X_test[:,list(sfs1.k_feature_idx_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc(y_sfs_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#efs lr acc\n",
    "clf.fit(X_train[:,list(efs1.best_idx_)],y_train)\n",
    "y_efs_pred = clf.predict(X_test[:,list(efs1.best_idx_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc(y_efs_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train[:,:],y_train)\n",
    "y_all_pred = clf.predict(X_test[:,:])\n",
    "acc(y_all_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ORebDiff  DRebDiff  AsstDiff    PFDiff   STLDiff    TODiff   BlkDiff  \\\n",
      "0 -1.414634  0.353659  1.951220 -3.439024  0.548780  2.317073 -0.146341   \n",
      "1  1.036585  1.731707  1.768293 -1.109756  0.512195 -0.682927 -0.536585   \n",
      "2  2.939024 -3.634146 -2.158537 -2.146341  0.134146 -0.292683  0.487805   \n",
      "3 -1.792683 -1.073171  0.304878 -0.402439  3.195122  4.000000  2.548780   \n",
      "4  0.170732  2.378049  1.585366 -0.841463 -1.634146  0.121951  2.463415   \n",
      "\n",
      "   x3PMDiff   FGPDiff   FTPDiff  WL  \n",
      "0  0.524390  0.015133  0.030245   1  \n",
      "1  0.402439 -0.005718  0.025008   1  \n",
      "2  0.634146 -0.018197 -0.034511   1  \n",
      "3 -0.560976  0.033874  0.013886   1  \n",
      "4 -0.585366  0.035610  0.002423   1  \n"
     ]
    }
   ],
   "source": [
    "read_df = pd.read_csv('finalDatasetFrom79.csv', sep=',')\n",
    "read_df = read_df.drop(['Year','TeamA','TeamB','PtDiff'],axis=1)\n",
    "read_df['WL'] = read_df['WL'].apply(result_to_numeric)\n",
    "print(read_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ORebDiff  DRebDiff  AsstDiff    PFDiff   STLDiff    TODiff   BlkDiff  \\\n",
      "0 -0.679655 -0.093778  0.485930 -1.183177  0.402658  1.621999 -0.181793   \n",
      "1  0.589625  0.600004  0.411367 -0.216360  0.377265 -0.279793 -0.464532   \n",
      "2  1.574738 -2.101447 -1.189259 -0.646619  0.114875 -0.032405  0.277659   \n",
      "3 -0.875415 -0.812118 -0.185140  0.077228  2.239388  2.688858  1.770879   \n",
      "4  0.141272  0.925406  0.336803 -0.104999 -1.112433  0.230444  1.709029   \n",
      "\n",
      "   x3PMDiff   FGPDiff   FTPDiff  WL  \n",
      "0  0.244336  0.359709  0.768017   1  \n",
      "1  0.165348 -0.754864  0.632071   1  \n",
      "2  0.315424 -1.421955 -0.912959   1  \n",
      "3 -0.458650  1.361487  0.343370   1  \n",
      "4 -0.474447  1.454279  0.045796   1  \n"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "df = pd.DataFrame(ss.fit_transform(read_df),columns = read_df.columns)\n",
    "df['WL'] = read_df['WL']\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train_large, X_test_large, y_train_large, y_test_large = train_test_split(df.values[:,:-1],df.values[:,-1],test_size=0.25,random_state=42,shuffle=False)\n",
    "\n",
    "y_train_large = y_train_large.astype('int')\n",
    "y_test_large = y_test_large.astype('int')\n",
    "\n",
    "print('Training dataset shape:', X_train_large.shape, y_train_large.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (374, 10) (374,)\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "X_train_large, y_train_large = df.values[:,:-1], df.values[:,-1]\n",
    "\n",
    "y_train_large = y_train_large.astype('int')\n",
    "#y_test_large = y_test_large.astype('int')\n",
    "\n",
    "print('Training dataset shape:', X_train_large.shape, y_train_large.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Features: 638/638[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.0s finished\n",
      "\n",
      "[2019-10-28 15:15:28] Features: 1/10 -- score: 0.7451612903225806[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.8s finished\n",
      "\n",
      "[2019-10-28 15:15:29] Features: 2/10 -- score: 0.7419354838709676[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.8s finished\n",
      "\n",
      "[2019-10-28 15:15:29] Features: 3/10 -- score: 0.732258064516129[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.7s finished\n",
      "\n",
      "[2019-10-28 15:15:30] Features: 4/10 -- score: 0.732258064516129[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.6s finished\n",
      "\n",
      "[2019-10-28 15:15:31] Features: 5/10 -- score: 0.7258064516129032[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.5s finished\n",
      "\n",
      "[2019-10-28 15:15:31] Features: 6/10 -- score: 0.7258064516129032[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.4s finished\n",
      "\n",
      "[2019-10-28 15:15:31] Features: 7/10 -- score: 0.7290322580645162[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.3s finished\n",
      "\n",
      "[2019-10-28 15:15:32] Features: 8/10 -- score: 0.7129032258064516[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.2s finished\n",
      "\n",
      "[2019-10-28 15:15:32] Features: 9/10 -- score: 0.7032258064516128[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "\n",
      "[2019-10-28 15:15:32] Features: 10/10 -- score: 0.667741935483871"
     ]
    }
   ],
   "source": [
    "# Build step forward feature selection\n",
    "efs2 = efs(clf,\n",
    "           min_features=1,\n",
    "           max_features=10,\n",
    "           scoring='accuracy',\n",
    "           print_progress=True,\n",
    "           cv=tscv(n_splits = 5))\n",
    "\n",
    "sfs2 = sfs(clf,\n",
    "           k_features='best',\n",
    "           scoring='accuracy',\n",
    "           verbose=2,\n",
    "           cv=tscv(n_splits = 5))\n",
    "\n",
    "# Perform SFFS\n",
    "efs2 = efs2.fit(X_train_large, y_train_large)\n",
    "\n",
    "#Perform SFFS\n",
    "sfs2 = sfs2.fit(X_train_large, y_train_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7419354838709677"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efs2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7451612903225806"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs2.k_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5, 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efs2.best_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs2.k_feature_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sfs lr acc\n",
    "clf.fit(X_train_large[:,list(sfs2.k_feature_idx_)],y_train_large)\n",
    "y_sfs_pred_large = clf.predict(X_test_large[:,list(sfs2.k_feature_idx_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc(y_sfs_pred_large,y_test_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#efs lr acc\n",
    "clf.fit(X_train_large[:,list(efs2.best_idx_)],y_train_large)\n",
    "y_efs_pred_large = clf.predict(X_test_large[:,list(efs2.best_idx_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc(y_efs_pred_large,y_test_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train_large[:,:],y_train_large)\n",
    "y_all_pred_large = clf.predict(X_test_large[:,:])\n",
    "acc(y_all_pred_large,y_test_large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   O_ORebDiff  O_DRebDiff  O_AsstDiff  O_PFDiff  O_STLDiff  O_TODiff  \\\n",
      "0   -0.852744    0.220118    0.725228 -1.624636   0.502332  1.219331   \n",
      "1    0.624856    1.077818    0.657237 -0.524262   0.468844 -0.359382   \n",
      "2    1.771649   -2.261899   -0.802283 -1.013957   0.122792 -0.154021   \n",
      "3   -1.080633   -0.667943    0.113317 -0.190117   2.924691  2.104951   \n",
      "4    0.102917    1.480102    0.589247 -0.397517  -1.495834  0.064175   \n",
      "\n",
      "   O_BlkDiff  O_x3PMDiff  O_FGPDiff  O_FTPDiff  D_ORebDiff  D_DRebDiff  \\\n",
      "0  -0.141657    0.239121   0.635920   1.072682    0.663973   -1.368963   \n",
      "1  -0.519410    0.183512  -0.240265   0.886943    0.567872    0.354402   \n",
      "2   0.472191    0.289170  -0.764677  -1.223977    0.366933   -1.077103   \n",
      "3   2.467195   -0.255804   1.423435   0.492501    1.057116   -2.223696   \n",
      "4   2.384562   -0.266926   1.496380   0.085936    0.838703   -1.424555   \n",
      "\n",
      "   D_AsstDiff  D_PFDiff  D_BlkDiff  D_x3PMDiff  D_FTPDiff  WL  \n",
      "0    1.177983 -0.134638  -0.576137    0.362318  -0.717179   1  \n",
      "1    0.037999  0.750125  -0.032008    0.024564   0.717716   1  \n",
      "2   -1.491478 -0.916819  -0.464111   -0.184229   1.833909   1  \n",
      "3   -0.147248  1.275853  -2.096500    0.116679  -0.744617   1  \n",
      "4    1.415479 -1.224563  -0.112027   -0.135102   0.450549   1  \n",
      "Index(['O_ORebDiff', 'O_DRebDiff', 'O_AsstDiff', 'O_PFDiff', 'O_STLDiff',\n",
      "       'O_TODiff', 'O_BlkDiff', 'O_x3PMDiff', 'O_FGPDiff', 'O_FTPDiff',\n",
      "       'D_ORebDiff', 'D_DRebDiff', 'D_AsstDiff', 'D_PFDiff', 'D_BlkDiff',\n",
      "       'D_x3PMDiff', 'D_FTPDiff', 'WL'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "df = pd.read_csv('completeFinalDatasetFrom79_Pruned.csv', sep=',')\n",
    "df = df.drop(['Year','TeamA','TeamB'],axis=1)\n",
    "df['WL'] = df['WL'].apply(result_to_numeric)\n",
    "print(df.head())\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   O_ORebDiff  O_DRebDiff  O_AsstDiff  O_PFDiff  O_STLDiff  O_TODiff  \\\n",
      "0   -1.414634    0.353659    1.951220 -3.439024   0.548780  2.317073   \n",
      "1    1.036585    1.731707    1.768293 -1.109756   0.512195 -0.682927   \n",
      "2    2.939024   -3.634146   -2.158537 -2.146341   0.134146 -0.292683   \n",
      "3   -1.792683   -1.073171    0.304878 -0.402439   3.195122  4.000000   \n",
      "4    0.170732    2.378049    1.585366 -0.841463  -1.634146  0.121951   \n",
      "\n",
      "   O_BlkDiff  O_x3PMDiff  O_FGPDiff  O_FTPDiff  ...  D_DRebDiff  D_AsstDiff  \\\n",
      "0  -0.146341    0.524390   0.015133   0.030245  ...   -2.402439    3.024390   \n",
      "1  -0.536585    0.402439  -0.005718   0.025008  ...    0.621951    0.097561   \n",
      "2   0.487805    0.634146  -0.018197  -0.034511  ...   -1.890244   -3.829268   \n",
      "3   2.548780   -0.560976   0.033874   0.013886  ...   -3.902439   -0.378049   \n",
      "4   2.463415   -0.585366   0.035610   0.002423  ...   -2.500000    3.634146   \n",
      "\n",
      "   D_PFDiff  D_STLDiff  D_TODiff  D_BlkDiff  D_x3PMDiff  D_FGPDiff  D_FTPDiff  \\\n",
      "0 -0.256098   2.280488 -1.207317  -0.439024    0.719512   0.000364  -0.011546   \n",
      "1  1.426829  -0.341463  0.841463  -0.024390    0.048780  -0.018831   0.011555   \n",
      "2 -1.743902  -0.609756  1.024390  -0.353659   -0.365854  -0.004658   0.029525   \n",
      "3  2.426829   1.731707  4.134146  -1.597561    0.231707  -0.009696  -0.011988   \n",
      "4 -2.329268  -1.036585 -2.963415  -0.085366   -0.268293  -0.006320   0.007254   \n",
      "\n",
      "   WL  \n",
      "0   1  \n",
      "1   1  \n",
      "2   1  \n",
      "3   1  \n",
      "4   1  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Index(['O_ORebDiff', 'O_DRebDiff', 'O_AsstDiff', 'O_PFDiff', 'O_STLDiff',\n",
      "       'O_TODiff', 'O_BlkDiff', 'O_x3PMDiff', 'O_FGPDiff', 'O_FTPDiff',\n",
      "       'D_ORebDiff', 'D_DRebDiff', 'D_AsstDiff', 'D_PFDiff', 'D_STLDiff',\n",
      "       'D_TODiff', 'D_BlkDiff', 'D_x3PMDiff', 'D_FGPDiff', 'D_FTPDiff', 'WL'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "read_df = pd.read_csv('completeFinalDatasetFrom79.csv', sep=',')\n",
    "read_df = read_df.drop(['Year','TeamA','TeamB','O_PtDiff','D_PtDiff'],axis=1)\n",
    "read_df['WL'] = read_df['WL'].apply(result_to_numeric)\n",
    "print(read_df.head())\n",
    "print(read_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   O_ORebDiff  O_DRebDiff  O_AsstDiff  O_PFDiff  O_STLDiff  O_TODiff  \\\n",
      "0   -0.679655   -0.093778    0.485930 -1.183177   0.402658  1.621999   \n",
      "1    0.589625    0.600004    0.411367 -0.216360   0.377265 -0.279793   \n",
      "2    1.574738   -2.101447   -1.189259 -0.646619   0.114875 -0.032405   \n",
      "3   -0.875415   -0.812118   -0.185140  0.077228   2.239388  2.688858   \n",
      "4    0.141272    0.925406    0.336803 -0.104999  -1.112433  0.230444   \n",
      "\n",
      "   O_BlkDiff  O_x3PMDiff  O_FGPDiff  O_FTPDiff  ...  D_DRebDiff  D_AsstDiff  \\\n",
      "0  -0.181793    0.244336   0.359709   0.768017  ...   -0.804917    1.469098   \n",
      "1  -0.464532    0.165348  -0.754864   0.632071  ...    0.619116    0.184956   \n",
      "2   0.277659    0.315424  -1.421955  -0.912959  ...   -0.563750   -1.537935   \n",
      "3   1.770879   -0.458650   1.361487   0.343370  ...   -1.511191   -0.023717   \n",
      "4   1.709029   -0.474447   1.454279   0.045796  ...   -0.850853    1.736628   \n",
      "\n",
      "   D_PFDiff  D_STLDiff  D_TODiff  D_BlkDiff  D_x3PMDiff  D_FGPDiff  D_FTPDiff  \\\n",
      "0 -0.158705   2.375509 -0.508823  -0.261466    1.289597   0.363178  -0.566910   \n",
      "1  0.697476  -0.257522  0.548204   0.179711    0.191872  -0.701225   0.763766   \n",
      "2 -0.915619  -0.526948  0.642581  -0.170635   -0.486722   0.084684   1.798887   \n",
      "3  1.206222   1.824409  2.246997  -1.494168    0.491251  -0.194677  -0.592355   \n",
      "4 -1.213421  -0.955581 -1.414846   0.114832   -0.327053  -0.007509   0.516004   \n",
      "\n",
      "   WL  \n",
      "0   1  \n",
      "1   1  \n",
      "2   1  \n",
      "3   1  \n",
      "4   1  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "df = pd.DataFrame(ss.fit_transform(read_df),columns = read_df.columns)\n",
    "df['WL'] = read_df['WL']\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (261, 17) (261,)\n",
      "Testing dataset shape: (113, 17) (113,)\n",
      "1    267\n",
      "0    107\n",
      "Name: WL, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "X_train_complete, X_test_complete, y_train_complete, y_test_complete = train_test_split(\n",
    "    df.values[:,:-1],\n",
    "    df.values[:,-1],\n",
    "    test_size=0.30,\n",
    "    random_state=42,\n",
    "    shuffle=False)\n",
    "\n",
    "y_train_complete = y_train_complete.astype('int')\n",
    "y_test_complete = y_test_complete.astype('int')\n",
    "\n",
    "print('Training dataset shape:', X_train_complete.shape, y_train_complete.shape)\n",
    "print('Testing dataset shape:', X_test_complete.shape, y_test_complete.shape)\n",
    "print(df['WL'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset shape: (374, 17) (374,)\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "X_train_complete, y_train_complete = df.values[:,:-1], df.values[:,-1]\n",
    "\n",
    "y_train_complete = y_train_large.astype('int')\n",
    "#y_test_large = y_test_large.astype('int')\n",
    "\n",
    "print('Training dataset shape:', X_train_complete.shape, y_train_complete.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:    1.6s finished\n",
      "\n",
      "[2019-10-28 15:54:55] Features: 1/17 -- score: 0.7441860465116279[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:    1.4s finished\n",
      "\n",
      "[2019-10-28 15:54:56] Features: 2/17 -- score: 0.7488372093023256[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:    1.3s finished\n",
      "\n",
      "[2019-10-28 15:54:58] Features: 3/17 -- score: 0.7441860465116279[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:    1.3s finished\n",
      "\n",
      "[2019-10-28 15:54:59] Features: 4/17 -- score: 0.7441860465116279[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:    1.2s finished\n",
      "\n",
      "[2019-10-28 15:55:00] Features: 5/17 -- score: 0.7488372093023256[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    1.4s finished\n",
      "\n",
      "[2019-10-28 15:55:02] Features: 6/17 -- score: 0.7488372093023256[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:    1.0s finished\n",
      "\n",
      "[2019-10-28 15:55:03] Features: 7/17 -- score: 0.7627906976744186[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    1.0s finished\n",
      "\n",
      "[2019-10-28 15:55:04] Features: 8/17 -- score: 0.772093023255814[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.9s finished\n",
      "\n",
      "[2019-10-28 15:55:04] Features: 9/17 -- score: 0.772093023255814[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    1.2s finished\n",
      "\n",
      "[2019-10-28 15:55:06] Features: 10/17 -- score: 0.7674418604651163[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    1.3s finished\n",
      "\n",
      "[2019-10-28 15:55:07] Features: 11/17 -- score: 0.7441860465116279[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.8s finished\n",
      "\n",
      "[2019-10-28 15:55:08] Features: 12/17 -- score: 0.7441860465116279[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.0s finished\n",
      "\n",
      "[2019-10-28 15:55:09] Features: 13/17 -- score: 0.758139534883721[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.5s finished\n",
      "\n",
      "[2019-10-28 15:55:09] Features: 14/17 -- score: 0.7441860465116279[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.4s finished\n",
      "\n",
      "[2019-10-28 15:55:09] Features: 15/17 -- score: 0.7255813953488371[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.3s finished\n",
      "\n",
      "[2019-10-28 15:55:10] Features: 16/17 -- score: 0.7116279069767442[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "\n",
      "[2019-10-28 15:55:10] Features: 17/17 -- score: 0.7162790697674419"
     ]
    }
   ],
   "source": [
    "# Build step forward feature selection\n",
    "\n",
    "sfs3 = sfs(clf,\n",
    "           k_features='best',\n",
    "           scoring='accuracy',\n",
    "           verbose=2,\n",
    "           cv=tscv(n_splits = 5))\n",
    "\n",
    "#Perform SFFS\n",
    "sfs3 = sfs3.fit(X_train_complete, y_train_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efs3 = efs(clf,\n",
    "           min_features=3,\n",
    "           max_features=10,\n",
    "           scoring='accuracy',\n",
    "           print_progress=True,\n",
    "           cv=tscv(n_splits = 5))\n",
    "\n",
    "# Perform SFFS\n",
    "efs3 = efs3.fit(X_train_complete, y_train_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efs3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.772093023255814"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs3.k_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efs3.best_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 4, 7, 9, 11, 12, 13, 14)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfs3.k_feature_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['O_DRebDiff', 'O_STLDiff', 'O_x3PMDiff', 'O_FTPDiff', 'D_DRebDiff',\n",
      "       'D_AsstDiff', 'D_PFDiff', 'D_BlkDiff'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Names of features\n",
    "colname = df.columns[[x for x in (list(sfs3.k_feature_idx_))]]\n",
    "print(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sfs lr acc\n",
    "clf.fit(X_train_complete[:,list(sfs3.k_feature_idx_)],y_train_complete)\n",
    "y_sfs_pred_complete = clf.predict(X_test_complete[:,list(sfs3.k_feature_idx_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6991150442477876"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc(y_sfs_pred_complete,y_test_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#efs lr acc\n",
    "clf.fit(X_train_complete[:,list(efs3.best_idx_)],y_train_complete)\n",
    "y_efs_pred_complete = clf.predict(X_test_complete[:,list(efs3.best_idx_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc(y_efs_pred_complete,y_test_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7079646017699115"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_complete[:,:],y_train_complete)\n",
    "y_all_pred_complete = clf.predict(X_test_complete[:,:])\n",
    "acc(y_all_pred_complete,y_test_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
